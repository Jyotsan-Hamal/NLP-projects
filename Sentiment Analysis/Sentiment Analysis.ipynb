{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b38c38e1-d6a0-4439-ba07-e5f3094349ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1addea9-0d9c-48a9-94f0-f36e3a4ffa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv', encoding='latin-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a62ba581-85db-48e8-aa7c-dc84faf5972b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th>Age of User</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population -2020</th>\n",
       "      <th>Land Area (Km²)</th>\n",
       "      <th>Density (P/Km²)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>morning</td>\n",
       "      <td>0-20</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>38928346</td>\n",
       "      <td>652860.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>noon</td>\n",
       "      <td>21-30</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2877797</td>\n",
       "      <td>27400.0</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>43851044</td>\n",
       "      <td>2381740.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>morning</td>\n",
       "      <td>46-60</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>77265</td>\n",
       "      <td>470.0</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>noon</td>\n",
       "      <td>60-70</td>\n",
       "      <td>Angola</td>\n",
       "      <td>32866272</td>\n",
       "      <td>1246700.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment Time of Tweet Age of User  \\\n",
       "0  I`d have responded, if I were going   neutral       morning        0-20   \n",
       "1                             Sooo SAD  negative          noon       21-30   \n",
       "2                          bullying me  negative         night       31-45   \n",
       "3                       leave me alone  negative       morning       46-60   \n",
       "4                        Sons of ****,  negative          noon       60-70   \n",
       "\n",
       "       Country  Population -2020  Land Area (Km²)  Density (P/Km²)  \n",
       "0  Afghanistan          38928346         652860.0               60  \n",
       "1      Albania           2877797          27400.0              105  \n",
       "2      Algeria          43851044        2381740.0               18  \n",
       "3      Andorra             77265            470.0              164  \n",
       "4       Angola          32866272        1246700.0               26  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed7e2981-a0a1-4dca-8f38-2c9729d80b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' is your DataFrame\n",
    "columns_to_drop = ['textID', 'selected_text', 'Time of Tweet','Age of User','Country','Population -2020','Land Area (Km²)','Density (P/Km²)']\n",
    "\n",
    "# Drop the specified columns\n",
    "new_data = data.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc361111-ccc0-4281-8550-623e1c3b68cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>All this flirting going on - The ATG smiles...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27481 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text sentiment\n",
       "0                    I`d have responded, if I were going   neutral\n",
       "1          Sooo SAD I will miss you here in San Diego!!!  negative\n",
       "2                              my boss is bullying me...  negative\n",
       "3                         what interview! leave me alone  negative\n",
       "4       Sons of ****, why couldn`t they put them on t...  negative\n",
       "...                                                  ...       ...\n",
       "27476   wish we could come see u on Denver  husband l...  negative\n",
       "27477   I`ve wondered about rake to.  The client has ...  negative\n",
       "27478   Yay good for both of you. Enjoy the break - y...  positive\n",
       "27479                         But it was worth it  ****.  positive\n",
       "27480     All this flirting going on - The ATG smiles...   neutral\n",
       "\n",
       "[27481 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ccb6546-5d2f-4e03-a8ba-bea1363b86b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2am feedings for the baby are fun when he is a...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "1      Sooo SAD I will miss you here in San Diego!!!  negative\n",
       "2                          my boss is bullying me...  negative\n",
       "3                     what interview! leave me alone  negative\n",
       "4   Sons of ****, why couldn`t they put them on t...  negative\n",
       "6  2am feedings for the baby are fun when he is a...  positive"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = new_data[new_data.sentiment != \"neutral\"]\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d41ad93d-166d-4aeb-bfe4-cb1d011d303a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'positive'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "980c2b87-a69a-4e0f-a418-80aaa703647d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_alphanumeric(text):\n",
    "    cleaned_text = ''\n",
    "    for char in text:\n",
    "        if char.isalnum() or char.isspace():\n",
    "            cleaned_text += char\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6491aafa-10f5-4d49-8ab1-3dab50d3473a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['text'] = new_data['text'].apply(lambda x: x.lower())\n",
    "new_data['text'] = new_data['text'].apply(remove_non_alphanumeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b79bcf1a-0f18-4ba0-b828-aa4900290cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sooo sad i will miss you here in san diego</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sons of  why couldnt they put them on the rel...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2am feedings for the baby are fun when he is a...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27475</th>\n",
       "      <td>enjoy ur night</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>wish we could come see u on denver  husband l...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>ive wondered about rake to  the client has ma...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>yay good for both of you enjoy the break  you...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>but it was worth it</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16363 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text sentiment\n",
       "1             sooo sad i will miss you here in san diego  negative\n",
       "2                                 my boss is bullying me  negative\n",
       "3                          what interview leave me alone  negative\n",
       "4       sons of  why couldnt they put them on the rel...  negative\n",
       "6      2am feedings for the baby are fun when he is a...  positive\n",
       "...                                                  ...       ...\n",
       "27475                                     enjoy ur night  positive\n",
       "27476   wish we could come see u on denver  husband l...  negative\n",
       "27477   ive wondered about rake to  the client has ma...  negative\n",
       "27478   yay good for both of you enjoy the break  you...  positive\n",
       "27479                              but it was worth it    positive\n",
       "\n",
       "[16363 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74156408-b52f-43a1-9cb3-6643d99bffcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85820\n",
      "77810\n"
     ]
    }
   ],
   "source": [
    "print(data[ data['sentiment'] == 'positive'].size) #Positive\n",
    "print(data[ data['sentiment'] == 'negative'].size) #Negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8245ca0a-7a7d-41c6-b1a4-23423bd3d645",
   "metadata": {},
   "source": [
    "### The reason for removing 'rt' might be to clean the text data, as 'rt' often appears in tweets to indicate a retweet. Removing it can be useful for certain types of text analysis or natural language processing tasks to focus on the core content of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4641cbe7-bf82-46fd-b0a1-19869d020999",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20204\\3383244808.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  row[0] = row[0].replace('rt',' ')\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20204\\3383244808.py:2: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  row[0] = row[0].replace('rt',' ')\n"
     ]
    }
   ],
   "source": [
    "for idx,row in new_data.iterrows():\n",
    "    row[0] = row[0].replace('rt',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac0e28ae-c7f4-4fe2-a485-aa71e3bf743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "max_fatures = 2000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(new_data['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fadeb818-0862-4000-b4e3-382365e2d6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...   98   11 1401]\n",
      " [   0    0    0 ... 1328    9   15]\n",
      " [   0    0    0 ...  371   15  440]\n",
      " ...\n",
      " [   0    0    0 ...  756    4   77]\n",
      " [   0    0    0 ...  213  589  742]\n",
      " [   0    0    0 ...   26  573    8]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X = tokenizer.texts_to_sequences(new_data['text'].values)\n",
    "X = pad_sequences(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97b80d54-78e3-4256-8bb0-88656e51eeda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[90].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a581dd8c-0dcf-4cc8-849e-982fd91d45f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 32, 128)           256000    \n",
      "                                                                 \n",
      " spatial_dropout1d (Spatial  (None, 32, 128)           0         \n",
      " Dropout1D)                                                      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 196)               254800    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 394       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 511194 (1.95 MB)\n",
      "Trainable params: 511194 (1.95 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "\n",
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "'''the Embedding layer is transforming each word in your text into a 128-dimensional vector. \n",
    "This transformation is learned during the training of your model. \n",
    "The output of the Embedding layer is a 2D vector with the length of the input sentence and the embedding dimension (128 in your case) \n",
    "for each word in the sentence.'''\n",
    "model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
    "\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "53dba432-34ea-4ead-acdf-632e3a19dce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11454, 32) (11454, 2)\n",
      "(4909, 32) (4909, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "Y = pd.get_dummies(new_data['sentiment']).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.3, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d328f8a4-a435-4e9d-85f5-8e3fd4fdf835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "358/358 - 36s - loss: 0.4420 - accuracy: 0.7808 - 36s/epoch - 100ms/step\n",
      "Epoch 2/40\n",
      "358/358 - 33s - loss: 0.2882 - accuracy: 0.8820 - 33s/epoch - 91ms/step\n",
      "Epoch 3/40\n",
      "358/358 - 28s - loss: 0.2477 - accuracy: 0.9011 - 28s/epoch - 77ms/step\n",
      "Epoch 4/40\n",
      "358/358 - 28s - loss: 0.2163 - accuracy: 0.9123 - 28s/epoch - 77ms/step\n",
      "Epoch 5/40\n",
      "358/358 - 28s - loss: 0.1896 - accuracy: 0.9268 - 28s/epoch - 78ms/step\n",
      "Epoch 6/40\n",
      "358/358 - 28s - loss: 0.1706 - accuracy: 0.9340 - 28s/epoch - 78ms/step\n",
      "Epoch 7/40\n",
      "358/358 - 28s - loss: 0.1522 - accuracy: 0.9406 - 28s/epoch - 77ms/step\n",
      "Epoch 8/40\n",
      "358/358 - 28s - loss: 0.1342 - accuracy: 0.9479 - 28s/epoch - 77ms/step\n",
      "Epoch 9/40\n",
      "358/358 - 28s - loss: 0.1234 - accuracy: 0.9512 - 28s/epoch - 77ms/step\n",
      "Epoch 10/40\n",
      "358/358 - 28s - loss: 0.1094 - accuracy: 0.9577 - 28s/epoch - 77ms/step\n",
      "Epoch 11/40\n",
      "358/358 - 28s - loss: 0.1044 - accuracy: 0.9606 - 28s/epoch - 78ms/step\n",
      "Epoch 12/40\n",
      "358/358 - 28s - loss: 0.0899 - accuracy: 0.9667 - 28s/epoch - 78ms/step\n",
      "Epoch 13/40\n",
      "358/358 - 28s - loss: 0.0865 - accuracy: 0.9676 - 28s/epoch - 77ms/step\n",
      "Epoch 14/40\n",
      "358/358 - 28s - loss: 0.0825 - accuracy: 0.9690 - 28s/epoch - 78ms/step\n",
      "Epoch 15/40\n",
      "358/358 - 28s - loss: 0.0703 - accuracy: 0.9759 - 28s/epoch - 77ms/step\n",
      "Epoch 16/40\n",
      "358/358 - 28s - loss: 0.0635 - accuracy: 0.9755 - 28s/epoch - 78ms/step\n",
      "Epoch 17/40\n",
      "358/358 - 28s - loss: 0.0575 - accuracy: 0.9801 - 28s/epoch - 77ms/step\n",
      "Epoch 18/40\n",
      "358/358 - 28s - loss: 0.0559 - accuracy: 0.9778 - 28s/epoch - 79ms/step\n",
      "Epoch 19/40\n",
      "358/358 - 32s - loss: 0.0486 - accuracy: 0.9819 - 32s/epoch - 89ms/step\n",
      "Epoch 20/40\n",
      "358/358 - 34s - loss: 0.0449 - accuracy: 0.9836 - 34s/epoch - 94ms/step\n",
      "Epoch 21/40\n",
      "358/358 - 33s - loss: 0.0443 - accuracy: 0.9823 - 33s/epoch - 91ms/step\n",
      "Epoch 22/40\n",
      "358/358 - 35s - loss: 0.0392 - accuracy: 0.9859 - 35s/epoch - 98ms/step\n",
      "Epoch 23/40\n",
      "358/358 - 34s - loss: 0.0347 - accuracy: 0.9868 - 34s/epoch - 96ms/step\n",
      "Epoch 24/40\n",
      "358/358 - 30s - loss: 0.0360 - accuracy: 0.9863 - 30s/epoch - 85ms/step\n",
      "Epoch 25/40\n",
      "358/358 - 30s - loss: 0.0328 - accuracy: 0.9875 - 30s/epoch - 85ms/step\n",
      "Epoch 26/40\n",
      "358/358 - 28s - loss: 0.0330 - accuracy: 0.9880 - 28s/epoch - 79ms/step\n",
      "Epoch 27/40\n",
      "358/358 - 29s - loss: 0.0311 - accuracy: 0.9882 - 29s/epoch - 80ms/step\n",
      "Epoch 28/40\n",
      "358/358 - 29s - loss: 0.0306 - accuracy: 0.9882 - 29s/epoch - 80ms/step\n",
      "Epoch 29/40\n",
      "358/358 - 29s - loss: 0.0238 - accuracy: 0.9904 - 29s/epoch - 80ms/step\n",
      "Epoch 30/40\n",
      "358/358 - 28s - loss: 0.0246 - accuracy: 0.9906 - 28s/epoch - 80ms/step\n",
      "Epoch 31/40\n",
      "358/358 - 29s - loss: 0.0259 - accuracy: 0.9905 - 29s/epoch - 80ms/step\n",
      "Epoch 32/40\n",
      "358/358 - 31s - loss: 0.0282 - accuracy: 0.9883 - 31s/epoch - 86ms/step\n",
      "Epoch 33/40\n",
      "358/358 - 29s - loss: 0.0267 - accuracy: 0.9900 - 29s/epoch - 82ms/step\n",
      "Epoch 34/40\n",
      "358/358 - 33s - loss: 0.0208 - accuracy: 0.9917 - 33s/epoch - 92ms/step\n",
      "Epoch 35/40\n",
      "358/358 - 32s - loss: 0.0238 - accuracy: 0.9913 - 32s/epoch - 91ms/step\n",
      "Epoch 36/40\n",
      "358/358 - 31s - loss: 0.0201 - accuracy: 0.9924 - 31s/epoch - 87ms/step\n",
      "Epoch 37/40\n",
      "358/358 - 31s - loss: 0.0221 - accuracy: 0.9917 - 31s/epoch - 87ms/step\n",
      "Epoch 38/40\n",
      "358/358 - 31s - loss: 0.0184 - accuracy: 0.9931 - 31s/epoch - 87ms/step\n",
      "Epoch 39/40\n",
      "358/358 - 31s - loss: 0.0152 - accuracy: 0.9933 - 31s/epoch - 87ms/step\n",
      "Epoch 40/40\n",
      "358/358 - 31s - loss: 0.0171 - accuracy: 0.9941 - 31s/epoch - 87ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x16328404dc0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model.fit(X_train, Y_train, epochs = 40, batch_size=batch_size, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93efd4c8-36f8-43dd-9aaf-b7dfb6b21b19",
   "metadata": {},
   "source": [
    "# Training the model using Pytorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6c7a0544-7e12-471a-9511-b2b977151c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "Epoch: 1/40............. Loss: 0.44195064902305603\n",
      "Epoch: 2/40............. Loss: 0.2798157334327698\n",
      "Epoch: 3/40............. Loss: 0.33801567554473877\n",
      "Epoch: 4/40............. Loss: 0.2740136981010437\n",
      "Epoch: 5/40............. Loss: 0.2281075119972229\n",
      "Epoch: 6/40............. Loss: 0.2732827067375183\n",
      "Epoch: 7/40............. Loss: 0.10638570040464401\n",
      "Epoch: 8/40............. Loss: 0.42052140831947327\n",
      "Epoch: 9/40............. Loss: 0.07918696850538254\n",
      "Epoch: 10/40............. Loss: 0.09327013790607452\n",
      "Epoch: 11/40............. Loss: 0.08769256621599197\n",
      "Epoch: 12/40............. Loss: 0.10565336793661118\n",
      "Epoch: 13/40............. Loss: 0.08638720214366913\n",
      "Epoch: 14/40............. Loss: 0.06775138527154922\n",
      "Epoch: 15/40............. Loss: 0.0324229896068573\n",
      "Epoch: 16/40............. Loss: 0.09184589982032776\n",
      "Epoch: 17/40............. Loss: 0.20899057388305664\n",
      "Epoch: 18/40............. Loss: 0.10351333767175674\n",
      "Epoch: 19/40............. Loss: 0.08520432561635971\n",
      "Epoch: 20/40............. Loss: 0.008810481987893581\n",
      "Epoch: 21/40............. Loss: 0.09352930635213852\n",
      "Epoch: 22/40............. Loss: 0.014479908160865307\n",
      "Epoch: 23/40............. Loss: 0.01234547421336174\n",
      "Epoch: 24/40............. Loss: 0.0777023658156395\n",
      "Epoch: 25/40............. Loss: 0.06148672103881836\n",
      "Epoch: 26/40............. Loss: 0.11270733922719955\n",
      "Epoch: 27/40............. Loss: 0.014654239639639854\n",
      "Epoch: 28/40............. Loss: 0.15665170550346375\n",
      "Epoch: 29/40............. Loss: 0.10055965930223465\n",
      "Epoch: 30/40............. Loss: 0.0071648359298706055\n",
      "Epoch: 31/40............. Loss: 0.0044388785026967525\n",
      "Epoch: 32/40............. Loss: 0.03912012651562691\n",
      "Epoch: 33/40............. Loss: 0.014164496213197708\n",
      "Epoch: 34/40............. Loss: 0.06502790004014969\n",
      "Epoch: 35/40............. Loss: 0.05960428714752197\n",
      "Epoch: 36/40............. Loss: 0.027095073834061623\n",
      "Epoch: 37/40............. Loss: 0.009428310208022594\n",
      "Epoch: 38/40............. Loss: 0.09211897104978561\n",
      "Epoch: 39/40............. Loss: 0.09366832673549652\n",
      "Epoch: 40/40............. Loss: 0.015722835436463356\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Check if GPU is available and if not, use CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Print whether GPU or CPU is being used\n",
    "print('Using', 'GPU' if device.type == 'cuda' else 'CPU')\n",
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMNet, self).__init__()\n",
    "        self.embed = nn.Embedding(max_fatures, embed_dim)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.lstm = nn.LSTM(embed_dim, lstm_out, batch_first=True, dropout=0.2)\n",
    "        self.dense = nn.Linear(lstm_out, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        x = self.dropout(x)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        x = self.dense(lstm_out[:, -1, :])\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Convert your data to PyTorch tensors\n",
    "X_train_torch = torch.tensor(X_train, dtype=torch.long).to(device)\n",
    "Y_train_torch = torch.tensor(Y_train, dtype=torch.float).to(device)\n",
    "\n",
    "X_test_torch = torch.tensor(X_test, dtype=torch.long).to(device)\n",
    "Y_test_torch = torch.tensor(Y_test, dtype=torch.float).to(device)\n",
    "\n",
    "# Create TensorDatasets for training and testing\n",
    "train_data = TensorDataset(X_train_torch, Y_train_torch)\n",
    "test_data = TensorDataset(X_test_torch, Y_test_torch)\n",
    "\n",
    "# Create DataLoaders for training and testing\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize the model, optimizer, and loss function\n",
    "py_model = LSTMNet().to(device)\n",
    "optimizer = torch.optim.Adam(py_model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(40):\n",
    "    for inputs, labels in train_loader:\n",
    "        py_model.zero_grad()\n",
    "        output = py_model(inputs)\n",
    "        loss = loss_fn(output, torch.max(labels, 1)[1])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch: {epoch+1}/40.............', end=' ')\n",
    "    print(f'Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "56423d05-fdeb-4e6b-804a-ccbcc46f4815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 4230/4909 (86%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Switch model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        output = model(inputs)\n",
    "        # sum up batch loss\n",
    "        test_loss += loss_fn(output, torch.max(labels, 1)[1]).item()\n",
    "        # get the index of the max log-probability\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(torch.max(labels, 1)[1].view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "\n",
    "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e7cbe527-152d-4734-8692-3ec7325991e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recession hit veronique branquinho she has to quit her company such a shame\n",
      "Negative sentiment\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Your sentence\n",
    "sentence = \"Recession Hit veronique branquinho, she has to quit her company, such a shame!\"\n",
    "sentence = sentence.lower()\n",
    "sentence = re.sub('[^a-zA-z0-9\\s]','',sentence)\n",
    "print(sentence)\n",
    "# Tokenize the sentence\n",
    "sentence = tokenizer.texts_to_sequences(sentence)\n",
    "\n",
    "# Pad the sequence\n",
    "sentence = pad_sequences(sentence, maxlen=X.shape[1])\n",
    "\n",
    "# Convert to tensor\n",
    "sentence = torch.tensor(sentence, dtype=torch.long).to(device)\n",
    "\n",
    "# Get the model's prediction\n",
    "prediction = py_model(sentence)\n",
    "\n",
    "# Print the prediction\n",
    "if torch.argmax(prediction) == 1:\n",
    "    print(\"Positive sentiment\")\n",
    "else:\n",
    "    print(\"Negative sentiment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "03f25d52-eaf1-4a25-bc8c-c19168486937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'sentiment.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d9e385-90b6-4a15-86e1-0400eeaf255c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
